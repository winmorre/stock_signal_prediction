{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69099f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading h5py-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /home/chief/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/chief/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/chief/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /home/chief/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/chief/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/chief/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/chief/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.64.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Downloading keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/chief/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/chief/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /home/chief/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.3.5)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Downloading optree-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m45.4/45.4 kB\u001B[0m \u001B[31m167.4 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/chief/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/chief/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chief/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/chief/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/chief/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/chief/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/chief/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/chief/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/chief/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/chief/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m589.8/589.8 MB\u001B[0m \u001B[31m2.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m0m eta \u001B[36m0:00:01\u001B[0m[36m0:00:02\u001B[0m\n",
      "\u001B[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m133.7/133.7 kB\u001B[0m \u001B[31m3.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mm eta \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.5/57.5 kB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading grpcio-1.64.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.6/5.6 MB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m0m eta \u001B[36m0:00:01\u001B[0m36m0:00:01\u001B[0mm\n",
      "\u001B[?25hDownloading h5py-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.4/5.4 MB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m0m eta \u001B[36m0:00:01\u001B[0m0:01\u001B[0m:01\u001B[0m\n",
      "\u001B[?25hDownloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m288.9 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m eta \u001B[36m0:00:01\u001B[0m[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.5/24.5 MB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m0m eta \u001B[36m0:00:01\u001B[0m[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m0m eta \u001B[36m0:00:01\u001B[0m0:01\u001B[0m:01\u001B[0m\n",
      "\u001B[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m65.5/65.5 kB\u001B[0m \u001B[31m2.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.5/5.5 MB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m0m eta \u001B[36m0:00:01\u001B[0m[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading tensorflow_io_gcs_filesystem-0.37.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.1/5.1 MB\u001B[0m \u001B[31m7.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m0m eta \u001B[36m0:00:01\u001B[0m0:01\u001B[0m:01\u001B[0m\n",
      "\u001B[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.6/6.6 MB\u001B[0m \u001B[31m6.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m0m eta \u001B[36m0:00:01\u001B[0m0:01\u001B[0m:01\u001B[0m\n",
      "\u001B[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (312 kB)\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m312.0/312.0 kB\u001B[0m \u001B[31m3.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.9.0\n",
      "    Uninstalling h5py-3.9.0:\n",
      "      Successfully uninstalled h5py-3.9.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.64.1 h5py-3.11.0 keras-3.3.3 libclang-18.1.1 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.3.0 optree-0.11.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.37.0 termcolor-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This setup leverages the strengths of both CNNs (for capturing local patterns) and \n",
    "BiLSTM with Attention (for capturing temporal dependencies and important features) to \n",
    "provide a robust solution for stock prediction. Adjust the input shape, hyperparameters, \n",
    "and data preprocessing steps as necessary for your specific dataset and prediction task.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0211218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, BatchNormalization,\n",
    "    Activation, Add, MaxPooling1D, Flatten, Dense, LSTM,\n",
    "    Bidirectional, Attention, Concatenate\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d6985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN with residula block\n",
    "def residual_block(x,filters,kernel_size=3):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters,kernel_size, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv1D(filters,kernel_size,padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([shortcut,x])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def create_cnn_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(64,3,padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = residual_block(x,64)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = residual_block(x,64)\n",
    "#     x = Flatten()(x)\n",
    "#     outputs = Dense(1)(x)\n",
    "#     model = Model(inputs,outputs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b19c54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define BiLSTM with Attention mechanism\n",
    "def attention_mech_layer(inputs):\n",
    "    q = Dense(128)(inputs)\n",
    "    k = Dense(128)(inputs)\n",
    "    v = Dense(128)(inputs)\n",
    "    attention_output = Attention()([q,k,v])\n",
    "    return attention_output\n",
    "\n",
    "def create_bilstm_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Bidirectional(LSTM(64,return_sequences=True))(inputs)\n",
    "    x = attention_mech_layer(x)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    model = Model(inputs,outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d014c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    cnn_model = create_cnn_model(input_shape)\n",
    "    bilstm_model = create_bilstm_model(cnn_model)\n",
    "    # check this part of the code\n",
    "    x = Dense(128,activation=\"relu\")(bilstm_model.output)\n",
    "    x = Dense(64,activation=\"relu\")(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    model = Model(inputs=[inputs],outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # load the data\n",
    "    input_shape = (100,1)\n",
    "    esemble_model = create_ensemble_model(input_shape)\n",
    "    esemble_model.compile(optimizer=Adam(learning_rate=0.001),loss='mse', metrics=['mae'])\n",
    "    \n",
    "    ensemble_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "    \n",
    "    # evaluate model\n",
    "    ensemble_model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {loss}, Test MAE: {mae}')\n",
    "    \n",
    "    predictions = ensemble_model.predict(X_test)\n",
    "    \n",
    "\n",
    "def evaluate_model(X_test,ytest):\n",
    "    return ensemble_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a15464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_bilstm_model(input_shape, conv_filters, lstm_units, dense_units,learning_rate):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    #CNN part\n",
    "    x = Conv1D(filters=conv_filters,kernel_size=3,padding=\"same\", activate=\"relu\")(inputs)\n",
    "    x=BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    # BiLSTM part\n",
    "    x= Bidirectional(LSTM(units=lstm_units,return_sequences=TRue))(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Dense part\n",
    "    x = Dense(units=dense_units,activation=\"relu\")(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    model = Model(inputs,outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),loss='mse',metrics=['mae'])\n",
    "    return model\n",
    "    \n",
    "\n",
    "# Define fitness function\n",
    "def fitness_function(hyperparams,input_shape,X_train,ytrain,x_val,y_val):\n",
    "    conv_filters, lstm_units,dense_units,learning_rate = hyperparams\n",
    "    model = create_cnn_bilstm_model(input_shape,conv_filters, lstm_units,dense_units, learning_rate)\n",
    "    \n",
    "    model.fit(X_train,ytrain,epoch=10,batch_size=32,validation_split=0.2,verbose=0)\n",
    "    loss, mae = model.evaluate(x_val,y_val,verbose=0)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "\n",
    "# Red deer optimization algorithm\n",
    "def red_deer_optimization(pop_size,num_generations,search_space,fitness_function):\n",
    "    # Initialize the population\n",
    "    population = np.random.uniform(low=search_space[\"low\"],high=search_space[\"high\"],size = (pop_size,len(search_space[\"low\"])))\n",
    "    \n",
    "    best_solution = None\n",
    "    best_fitness = float('inf')\n",
    "    \n",
    "    for generation in range(num_generations):\n",
    "        # evaluate the fitness of each solution\n",
    "        fitness_values = np.array([fitness_function(ind) for ind in population])\n",
    "        min_fitness_idx = np.argmin(fitness_values)\n",
    "        if fitness_values[min_fitness_idx] < best_fitness:\n",
    "            best_fitness = fitness_values[min_fitness_idx]\n",
    "            best_solution = population[min_fitness_idx]\n",
    "        \n",
    "        # apply RDO algorithm steps (simplified for illustration)\n",
    "        new_population = []\n",
    "        for i in range(pop_size//2):\n",
    "            male = population[i]\n",
    "            female = population[pop_size // 2 +i]\n",
    "            \n",
    "            # Roaring: small mutation\n",
    "            male_offspring = male + np.random.normal(0,0.1,size=male.shape)\n",
    "            female_offspring = female + np.random.normal(0,0.1,size=female.shape)\n",
    "            \n",
    "            # Mate crossover\n",
    "            offspring = (male+female)/2\n",
    "            \n",
    "            # Add new individuals to population\n",
    "            new_population.extend([male_offspring,female_offspring,offspring])\n",
    "        \n",
    "        #Select the new population for the next generation\n",
    "        population = np.array(new_population[:pop_size])\n",
    "    return best_solution, best_fitness\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "search_space = {\n",
    "    'low': [16, 16, 16, 1e-5],  # Min values for conv_filters, lstm_units, dense_units, learning_rate\n",
    "    'high': [128, 128, 128, 1e-2]  # Max values for conv_filters, lstm_units, dense_units, learning_rate\n",
    "}\n",
    "\n",
    "best_solution, best_fitness = red_deer_optimization(\n",
    "    pop_size=20,\n",
    "    num_generations=50,\n",
    "    search_space=search_space,\n",
    "    fitness_function=fitness_function\n",
    ")\n",
    "\n",
    "print(f'Best hyperparameters: {best_solution}')\n",
    "print(f'Best validation MAE: {best_fitness}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDA:\n",
    "    def __init__(self, num_agents, max_iter, train_data,label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
